{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27eece62",
   "metadata": {},
   "source": [
    "# Thesis Experiment (Part A + Part B MVP)\n",
    "\n",
    "Minimal notebook to run the thesis experiment end-to-end using existing project functions from `src/sharpe_mc.py`.\n",
    "\n",
    "Outputs saved under `outputs/thesis_mvp/`:\n",
    "- `results_partA.parquet` (and CSV fallback)\n",
    "- `results_partB_pit.parquet` (and CSV fallback)\n",
    "- `model_fit_summary.json`\n",
    "- `environment_versions.json`\n",
    "- figures (`.png` and `.pdf`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcd5957b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"python\": \"3.12.1 (main, Jul 10 2025, 11:57:50) [GCC 13.3.0]\",\n",
      "  \"platform\": \"Linux-6.8.0-1030-azure-x86_64-with-glibc2.39\",\n",
      "  \"packages\": {\n",
      "    \"numpy\": \"2.3.4\",\n",
      "    \"pandas\": \"2.3.3\",\n",
      "    \"scipy\": \"1.16.3\",\n",
      "    \"matplotlib\": \"3.10.3\",\n",
      "    \"tqdm\": \"not-installed\",\n",
      "    \"arch\": \"8.0.0\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import platform\n",
    "import random\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import importlib.metadata as ilmd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except Exception:\n",
    "    def tqdm(x, **kwargs):\n",
    "        return x\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "RUN_DIR = Path(\"outputs/thesis_mvp\").resolve()\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SAVED_ARTIFACTS = []\n",
    "\n",
    "\n",
    "def pkg_version(name: str) -> str:\n",
    "    try:\n",
    "        return ilmd.version(name)\n",
    "    except Exception:\n",
    "        return \"not-installed\"\n",
    "\n",
    "\n",
    "versions = {\n",
    "    \"python\": sys.version,\n",
    "    \"platform\": platform.platform(),\n",
    "    \"packages\": {\n",
    "        \"numpy\": pkg_version(\"numpy\"),\n",
    "        \"pandas\": pkg_version(\"pandas\"),\n",
    "        \"scipy\": pkg_version(\"scipy\"),\n",
    "        \"matplotlib\": pkg_version(\"matplotlib\"),\n",
    "        \"tqdm\": pkg_version(\"tqdm\"),\n",
    "        \"arch\": pkg_version(\"arch\"),\n",
    "    },\n",
    "}\n",
    "print(json.dumps(versions, indent=2))\n",
    "\n",
    "versions_path = RUN_DIR / \"environment_versions.json\"\n",
    "versions_path.write_text(json.dumps(versions, indent=2), encoding=\"utf-8\")\n",
    "SAVED_ARTIFACTS.append(str(versions_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1b7647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"R\": 1000,\n",
      "  \"seed\": 0,\n",
      "  \"n_list\": [\n",
      "    120,\n",
      "    240,\n",
      "    1200\n",
      "  ],\n",
      "  \"S_true_list\": [\n",
      "    0.0,\n",
      "    0.5\n",
      "  ],\n",
      "  \"alpha\": 0.05,\n",
      "  \"burn_B\": 500,\n",
      "  \"t_df\": 5,\n",
      "  \"garch_alpha\": 0.05,\n",
      "  \"garch_beta\": 0.9,\n",
      "  \"DSR_M\": null,\n",
      "  \"max_workers\": 1,\n",
      "  \"cache_dir\": \"/workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/cache\",\n",
      "  \"figures_dir\": \"/workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures\",\n",
      "  \"factors_start_date\": \"1926-07-01\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    \"R\": 1000,\n",
    "    \"seed\": 0,\n",
    "    \"n_list\": [120, 240, 1200],\n",
    "    \"S_true_list\": [0.0,0.25,0.5,0.75,1],\n",
    "    \"alpha\": 0.05,\n",
    "    \"burn_B\": 500,\n",
    "    \"t_df\": 5,\n",
    "    \"garch_alpha\": 0.05,\n",
    "    \"garch_beta\": 0.90,\n",
    "    \"DSR_M\": None,\n",
    "    \"max_workers\": 4,\n",
    "    \"cache_dir\": str((RUN_DIR / \"cache\").resolve()),\n",
    "    \"figures_dir\": str((RUN_DIR / \"figures\").resolve()),\n",
    "    \"factors_start_date\": \"1926-07-01\",\n",
    "}\n",
    "\n",
    "if CONFIG[\"t_df\"] <= 4:\n",
    "    raise ValueError(\"t_df must be > 4\")\n",
    "if CONFIG[\"garch_alpha\"] + CONFIG[\"garch_beta\"] >= 1:\n",
    "    raise ValueError(\"garch_alpha + garch_beta must be < 1\")\n",
    "\n",
    "CACHE_DIR = Path(CONFIG[\"cache_dir\"])\n",
    "FIG_DIR = Path(CONFIG[\"figures_dir\"])\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(json.dumps(CONFIG, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4fb3914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using project root: /workspaces/finance-data-download-test\n",
      "Using module: /workspaces/finance-data-download-test/src/sharpe_mc.py\n"
     ]
    }
   ],
   "source": [
    "# Project integration (ready-made functions only)\n",
    "cwd = Path.cwd().resolve()\n",
    "project_root = None\n",
    "for p in [cwd, *cwd.parents]:\n",
    "    if (p / \"src\" / \"sharpe_mc.py\").exists():\n",
    "        project_root = p\n",
    "        if str(p) not in sys.path:\n",
    "            sys.path.insert(0, str(p))\n",
    "        break\n",
    "\n",
    "if project_root is None:\n",
    "    raise RuntimeError(\"Could not find project root with src/sharpe_mc.py\")\n",
    "\n",
    "from src import sharpe_mc\n",
    "from finance_data.french import load_us_research_factors_wide\n",
    "\n",
    "print(\"Using project root:\", project_root)\n",
    "print(\"Using module:\", sharpe_mc.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27bf16f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small helper utilities (kept minimal)\n",
    "OUTPUT_COLS = [\n",
    "    \"dgp\", \"n\", \"S_true\", \"method\", \"bias\", \"rmse\", \"coverage_95\",\n",
    "    \"reject_rate_H0_S_le_0\", \"se_ratio\", \"psr_reject_rate\", \"dsr_reject_rate\",\n",
    "]\n",
    "\n",
    "\n",
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "def save_df(df: pd.DataFrame, stem: str) -> list[Path]:\n",
    "    paths = []\n",
    "    pq = RUN_DIR / f\"{stem}.parquet\"\n",
    "    csv = RUN_DIR / f\"{stem}.csv\"\n",
    "    try:\n",
    "        df.to_parquet(pq, index=False)\n",
    "        paths.append(pq)\n",
    "    except Exception:\n",
    "        pass\n",
    "    df.to_csv(csv, index=False)\n",
    "    paths.append(csv)\n",
    "    for p in paths:\n",
    "        SAVED_ARTIFACTS.append(str(p.resolve()))\n",
    "    return paths\n",
    "\n",
    "\n",
    "def load_cached_df(stem: str) -> pd.DataFrame | None:\n",
    "    pq = CACHE_DIR / f\"{stem}.parquet\"\n",
    "    csv = CACHE_DIR / f\"{stem}.csv\"\n",
    "    if pq.exists():\n",
    "        try:\n",
    "            return pd.read_parquet(pq)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if csv.exists():\n",
    "        return pd.read_csv(csv)\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_cached_df(df: pd.DataFrame, stem: str) -> Path:\n",
    "    pq = CACHE_DIR / f\"{stem}.parquet\"\n",
    "    csv = CACHE_DIR / f\"{stem}.csv\"\n",
    "    try:\n",
    "        df.to_parquet(pq, index=False)\n",
    "        return pq\n",
    "    except Exception:\n",
    "        df.to_csv(csv, index=False)\n",
    "        return csv\n",
    "\n",
    "\n",
    "def save_fig(fig: plt.Figure, stem: str) -> None:\n",
    "    png = FIG_DIR / f\"{stem}.png\"\n",
    "    pdf = FIG_DIR / f\"{stem}.pdf\"\n",
    "    fig.savefig(png, dpi=160, bbox_inches=\"tight\")\n",
    "    fig.savefig(pdf, bbox_inches=\"tight\")\n",
    "    SAVED_ARTIFACTS.extend([str(png.resolve()), str(pdf.resolve())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73625134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSR skipped by default (set CONFIG['DSR_M'] to enable).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dgp</th>\n",
       "      <th>n</th>\n",
       "      <th>S_true</th>\n",
       "      <th>method</th>\n",
       "      <th>bias</th>\n",
       "      <th>rmse</th>\n",
       "      <th>coverage_95</th>\n",
       "      <th>reject_rate_H0_S_le_0</th>\n",
       "      <th>se_ratio</th>\n",
       "      <th>psr_reject_rate</th>\n",
       "      <th>dsr_reject_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>garch11_t</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dsr</td>\n",
       "      <td>-0.001151</td>\n",
       "      <td>0.092662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>garch11_t</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>hac_newey_west</td>\n",
       "      <td>-0.001151</td>\n",
       "      <td>0.092662</td>\n",
       "      <td>0.926000</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.951211</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>garch11_t</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>iid_normal_analytic</td>\n",
       "      <td>-0.001151</td>\n",
       "      <td>0.092662</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.986850</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>garch11_t</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>psr</td>\n",
       "      <td>-0.001151</td>\n",
       "      <td>0.092662</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.986850</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>garch11_t</td>\n",
       "      <td>120</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>dsr</td>\n",
       "      <td>0.022526</td>\n",
       "      <td>0.136823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>iid_t</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>psr</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.029550</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.978857</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>iid_t</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>dsr</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.034829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>iid_t</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>hac_newey_west</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.034829</td>\n",
       "      <td>0.947000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>iid_t</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>iid_normal_analytic</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.034829</td>\n",
       "      <td>0.921000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.879041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>iid_t</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>psr</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.034829</td>\n",
       "      <td>0.921000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.879041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows \u00d7 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          dgp     n   S_true               method      bias     rmse  coverage_95  reject_rate_H0_S_le_0  se_ratio  psr_reject_rate  dsr_reject_rate\n",
       "0   garch11_t   120 0.000000                  dsr -0.001151 0.092662          NaN                    NaN       NaN              NaN              NaN\n",
       "1   garch11_t   120 0.000000       hac_newey_west -0.001151 0.092662     0.926000               0.062000  0.951211         0.050000              NaN\n",
       "2   garch11_t   120 0.000000  iid_normal_analytic -0.001151 0.092662     0.945000               0.050000  0.986850         0.050000              NaN\n",
       "3   garch11_t   120 0.000000                  psr -0.001151 0.092662     0.945000               0.050000  0.986850         0.050000              NaN\n",
       "4   garch11_t   120 0.500000                  dsr  0.022526 0.136823          NaN                    NaN       NaN              NaN              NaN\n",
       "..        ...   ...      ...                  ...       ...      ...          ...                    ...       ...              ...              ...\n",
       "67      iid_t  1200 0.000000                  psr  0.001991 0.029550     0.937000               0.062000  0.978857         0.062000              NaN\n",
       "68      iid_t  1200 0.500000                  dsr  0.000445 0.034829          NaN                    NaN       NaN              NaN              NaN\n",
       "69      iid_t  1200 0.500000       hac_newey_west  0.000445 0.034829     0.947000               1.000000  0.969117         1.000000              NaN\n",
       "70      iid_t  1200 0.500000  iid_normal_analytic  0.000445 0.034829     0.921000               1.000000  0.879041         1.000000              NaN\n",
       "71      iid_t  1200 0.500000                  psr  0.000445 0.034829     0.921000               1.000000  0.879041         1.000000              NaN\n",
       "\n",
       "[72 rows x 11 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part A: Monte Carlo calibration (using sharpe_mc.run_experiment directly)\n",
    "set_seed(CONFIG[\"seed\"])\n",
    "\n",
    "cache_key = (\n",
    "    f\"partA_R{CONFIG['R']}_seed{CONFIG['seed']}_df{CONFIG['t_df']}_\"\n",
    "    f\"ga{CONFIG['garch_alpha']}_gb{CONFIG['garch_beta']}_burn{CONFIG['burn_B']}_\"\n",
    "    f\"alpha{CONFIG['alpha']}_n{','.join(map(str, CONFIG['n_list']))}_\"\n",
    "    f\"S{','.join(map(str, CONFIG['S_true_list']))}\"\n",
    ")\n",
    "\n",
    "partA_raw = load_cached_df(cache_key)\n",
    "if partA_raw is None:\n",
    "    rows = sharpe_mc.run_experiment(\n",
    "        dgps=(\"iid_normal\", \"iid_t5\", \"garch11_t5\"),\n",
    "        n_grid=tuple(CONFIG[\"n_list\"]),\n",
    "        s_true_grid=tuple(CONFIG[\"S_true_list\"]),\n",
    "        reps=int(CONFIG[\"R\"]),\n",
    "        seed=int(CONFIG[\"seed\"]),\n",
    "        sigma=1.0,\n",
    "        df=int(CONFIG[\"t_df\"]),\n",
    "        alpha=float(CONFIG[\"garch_alpha\"]),\n",
    "        beta=float(CONFIG[\"garch_beta\"]),\n",
    "        burn=int(CONFIG[\"burn_B\"]),\n",
    "        n_trials=int(CONFIG[\"DSR_M\"]) if CONFIG[\"DSR_M\"] is not None else sharpe_mc.DEFAULT_N_TRIALS,\n",
    "        max_workers=int(CONFIG[\"max_workers\"]),\n",
    "        run_sanity=False,\n",
    "    )\n",
    "    partA_raw = pd.DataFrame(rows)\n",
    "    save_cached_df(partA_raw, cache_key)\n",
    "\n",
    "# Rename to thesis labels\n",
    "results_partA = partA_raw.copy()\n",
    "results_partA[\"dgp\"] = results_partA[\"dgp\"].replace({\n",
    "    \"iid_t5\": \"iid_t\",\n",
    "    \"garch11_t5\": \"garch11_t\",\n",
    "})\n",
    "results_partA[\"method\"] = results_partA[\"method\"].replace({\n",
    "    \"naive_asymptotic\": \"iid_normal_analytic\",\n",
    "    \"robust_hac\": \"hac_newey_west\",\n",
    "})\n",
    "\n",
    "# DSR: skip by default\n",
    "if CONFIG[\"DSR_M\"] is None:\n",
    "    print(\"DSR skipped by default (set CONFIG['DSR_M'] to enable).\")\n",
    "    results_partA[\"dsr_reject_rate\"] = np.nan\n",
    "    dsr_mask = results_partA[\"method\"].eq(\"dsr\")\n",
    "    results_partA.loc[dsr_mask, [\n",
    "        \"coverage_95\", \"reject_rate_H0_S_le_0\", \"se_ratio\", \"psr_reject_rate\", \"dsr_reject_rate\"\n",
    "    ]] = np.nan\n",
    "\n",
    "results_partA = results_partA[OUTPUT_COLS].sort_values([\"dgp\", \"n\", \"S_true\", \"method\"]).reset_index(drop=True)\n",
    "results_partA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04f1bea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Part A:\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/results_partA.csv\n"
     ]
    }
   ],
   "source": [
    "# Part A: save result table\n",
    "paths = save_df(results_partA, \"results_partA\")\n",
    "print(\"Saved Part A:\")\n",
    "for p in paths:\n",
    "    print(\"-\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51cb2986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>check</th>\n",
       "      <th>value</th>\n",
       "      <th>pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iid normal coverage (n=1200, S=0)</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>standardized t variance ~ 1</td>\n",
       "      <td>0.996854</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GARCH sigma_t^2 positive</td>\n",
       "      <td>0.599336</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               check    value  pass\n",
       "0  iid normal coverage (n=1200, S=0) 0.954000  True\n",
       "1        standardized t variance ~ 1 0.996854  True\n",
       "2           GARCH sigma_t^2 positive 0.599336  True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part A sanity checks\n",
    "checks = []\n",
    "\n",
    "cov = results_partA[\n",
    "    (results_partA[\"dgp\"] == \"iid_normal\")\n",
    "    & (results_partA[\"n\"] == 1200)\n",
    "    & (results_partA[\"S_true\"] == 0.0)\n",
    "    & (results_partA[\"method\"] == \"iid_normal_analytic\")\n",
    "][\"coverage_95\"]\n",
    "\n",
    "if len(cov) == 1:\n",
    "    value = float(cov.iloc[0])\n",
    "    checks.append({\"check\": \"iid normal coverage (n=1200, S=0)\", \"value\": value, \"pass\": abs(value - 0.95) <= 0.02})\n",
    "else:\n",
    "    checks.append({\"check\": \"iid normal coverage (n=1200, S=0)\", \"value\": np.nan, \"pass\": False})\n",
    "\n",
    "rng = np.random.default_rng(CONFIG[\"seed\"] + 77)\n",
    "t_big = sharpe_mc.simulate_iid_t5(n=200_000, mu=0.0, sigma=1.0, rng=rng, df=int(CONFIG[\"t_df\"]))\n",
    "var_t = float(np.var(t_big, ddof=1))\n",
    "checks.append({\"check\": \"standardized t variance ~ 1\", \"value\": var_t, \"pass\": abs(var_t - 1.0) <= 0.08})\n",
    "\n",
    "# GARCH sigma_t^2 positivity via direct recursion\n",
    "nu = float(CONFIG[\"t_df\"])\n",
    "a = float(CONFIG[\"garch_alpha\"])\n",
    "b = float(CONFIG[\"garch_beta\"])\n",
    "omega = 1.0 - a - b\n",
    "z = np.random.default_rng(CONFIG[\"seed\"] + 88).standard_t(df=nu, size=5000) / np.sqrt(nu / (nu - 2.0))\n",
    "h = np.empty_like(z)\n",
    "eps_prev = 0.0\n",
    "h_prev = 1.0\n",
    "for i in range(len(z)):\n",
    "    h_i = max(omega + a * eps_prev**2 + b * h_prev, 1e-14)\n",
    "    eps_i = np.sqrt(h_i) * z[i]\n",
    "    h[i] = h_i\n",
    "    h_prev = h_i\n",
    "    eps_prev = eps_i\n",
    "checks.append({\"check\": \"GARCH sigma_t^2 positive\", \"value\": float(h.min()), \"pass\": bool((h > 0).all())})\n",
    "\n",
    "sanity_df = pd.DataFrame(checks)\n",
    "sanity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56dcd3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Part A coverage figures\n"
     ]
    }
   ],
   "source": [
    "# Part A plot: coverage vs n by method (one figure per DGP)\n",
    "for dgp in [\"iid_normal\", \"iid_t\", \"garch11_t\"]:\n",
    "    fig, axes = plt.subplots(1, len(CONFIG[\"S_true_list\"]), figsize=(6 * len(CONFIG[\"S_true_list\"]), 4), sharey=True)\n",
    "    if len(CONFIG[\"S_true_list\"]) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, s_true in zip(axes, CONFIG[\"S_true_list\"]):\n",
    "        sub = results_partA[(results_partA[\"dgp\"] == dgp) & (results_partA[\"S_true\"] == float(s_true))]\n",
    "        for method in [\"iid_normal_analytic\", \"hac_newey_west\", \"psr\", \"dsr\"]:\n",
    "            m = sub[sub[\"method\"] == method].sort_values(\"n\")\n",
    "            y = m[\"coverage_95\"].to_numpy(dtype=float)\n",
    "            if np.isfinite(y).any():\n",
    "                ax.plot(m[\"n\"], y, marker=\"o\", label=method)\n",
    "        ax.axhline(0.95, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "        ax.set_title(f\"{dgp} | S_true={s_true}\")\n",
    "        ax.set_xlabel(\"n\")\n",
    "        ax.set_ylabel(\"coverage_95\")\n",
    "        ax.set_xticks(CONFIG[\"n_list\"])\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    if handles:\n",
    "        fig.legend(handles, labels, loc=\"upper center\", ncol=min(4, len(labels)))\n",
    "    fig.tight_layout()\n",
    "    save_fig(fig, f\"partA_coverage_{dgp}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "print(\"Saved Part A coverage figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78dbc270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Part A reject-rate figures\n"
     ]
    }
   ],
   "source": [
    "# Part A plot: reject rate vs n by method (one figure per DGP)\n",
    "for dgp in [\"iid_normal\", \"iid_t\", \"garch11_t\"]:\n",
    "    fig, axes = plt.subplots(1, len(CONFIG[\"S_true_list\"]), figsize=(6 * len(CONFIG[\"S_true_list\"]), 4), sharey=True)\n",
    "    if len(CONFIG[\"S_true_list\"]) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, s_true in zip(axes, CONFIG[\"S_true_list\"]):\n",
    "        sub = results_partA[(results_partA[\"dgp\"] == dgp) & (results_partA[\"S_true\"] == float(s_true))]\n",
    "        for method in [\"iid_normal_analytic\", \"hac_newey_west\", \"psr\", \"dsr\"]:\n",
    "            m = sub[sub[\"method\"] == method].sort_values(\"n\")\n",
    "            y = m[\"reject_rate_H0_S_le_0\"].to_numpy(dtype=float)\n",
    "            if np.isfinite(y).any():\n",
    "                ax.plot(m[\"n\"], y, marker=\"o\", label=method)\n",
    "        ax.set_title(f\"{dgp} | S_true={s_true}\")\n",
    "        ax.set_xlabel(\"n\")\n",
    "        ax.set_ylabel(\"reject_rate_H0_S_le_0\")\n",
    "        ax.set_xticks(CONFIG[\"n_list\"])\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    if handles:\n",
    "        fig.legend(handles, labels, loc=\"upper center\", ncol=min(4, len(labels)))\n",
    "    fig.tight_layout()\n",
    "    save_fig(fig, f\"partA_reject_{dgp}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "print(\"Saved Part A reject-rate figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a71a30be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage:\n",
      "Start 1926-07-31 End 2025-09-30 N obs 1191\n",
      "Part B ready: T=1191, train=834, holdout=357, windows=1, n=240\n"
     ]
    }
   ],
   "source": [
    "# Part B: load market return series from Fama-French and split train/holdout\n",
    "partB_ready = False\n",
    "partB_reason = \"\"\n",
    "partB_n = 240\n",
    "\n",
    "try:\n",
    "    # Fetch Mkt-RF and RF back to 1926 (monthly, decimals)\n",
    "    factors_wide, rf = load_us_research_factors_wide(start_date=CONFIG[\"factors_start_date\"])\n",
    "    factors_wide = factors_wide.rename(columns={\"Mkt-RF\": \"Mkt_RF\"}) if \"Mkt-RF\" in factors_wide.columns else factors_wide\n",
    "\n",
    "    mkt_excess = factors_wide[\"Mkt_RF\"].dropna()\n",
    "    rf = rf.reindex(mkt_excess.index)\n",
    "    mkt_total = mkt_excess + rf\n",
    "\n",
    "    # Rescale return series to percent units.\n",
    "    mkt_excess = mkt_excess * 100.0\n",
    "    rf = rf * 100.0\n",
    "    mkt_total = mkt_total * 100.0\n",
    "\n",
    "    print(\"Coverage:\")\n",
    "    print(\"Start\", mkt_excess.index.min().date(), \"End\", mkt_excess.index.max().date(), \"N obs\", mkt_excess.shape[0])\n",
    "\n",
    "    # Part B uses the excess-return series for Sharpe inference\n",
    "    series = mkt_excess\n",
    "\n",
    "    T = len(series)\n",
    "    train_len = int(round(0.70 * T))\n",
    "    holdout_len = T - train_len\n",
    "\n",
    "    train = series.iloc[:train_len]\n",
    "    holdout = series.iloc[train_len:]\n",
    "\n",
    "    n_windows = len(holdout) // partB_n\n",
    "    if n_windows < 1:\n",
    "        partB_reason = f\"Skipped Part B: holdout has no disjoint n={partB_n} window\"\n",
    "        print(partB_reason)\n",
    "    else:\n",
    "        holdout_use = holdout.iloc[: n_windows * partB_n]\n",
    "        obs_rows = []\n",
    "        for j in range(n_windows):\n",
    "            w = holdout_use.iloc[j * partB_n : (j + 1) * partB_n]\n",
    "            s_hat, _, _ = sharpe_mc.sharpe_ratio(w.to_numpy(dtype=float))\n",
    "            obs_rows.append({\"window_id\": j, \"S_obs\": float(s_hat)})\n",
    "        obs_windows = pd.DataFrame(obs_rows)\n",
    "        partB_ready = True\n",
    "        print(f\"Part B ready: T={T}, train={train_len}, holdout={holdout_len}, windows={n_windows}, n={partB_n}\")\n",
    "except Exception as e:\n",
    "    partB_reason = f\"Skipped Part B: failed to load Fama-French factors ({e})\"\n",
    "    print(partB_reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8632e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/arch/univariate/base.py:694: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
      "estimating the model parameters. The scale of y is 0.003138. Parameter\n",
      "estimation work better when this value is between 1 and 1000. The recommended\n",
      "rescaling is 10 * y.\n",
      "\n",
      "This warning can be disabled by either rescaling y before initializing the\n",
      "model or by setting rescale=False.\n",
      "\n",
      "  self._check_scale(resids)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Part B:\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/results_partB_pit.csv\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/model_fit_summary.json\n"
     ]
    }
   ],
   "source": [
    "# Part B: fit 3 models, bootstrap Sharpe distribution, PIT diagnostics\n",
    "partB_rows = []\n",
    "fit_summary = {}\n",
    "\n",
    "if not partB_ready:\n",
    "    results_partB = pd.DataFrame(columns=[\n",
    "        \"model\", \"window_id\", \"S_obs\", \"pit_u\", \"ks_stat\", \"ks_pvalue\", \"pit_score\", \"n_windows\", \"n_boot\"\n",
    "    ])\n",
    "    fit_summary = {\"status\": \"skipped\", \"reason\": partB_reason}\n",
    "else:\n",
    "    train_arr = train.to_numpy(dtype=float)\n",
    "    Rb = int(CONFIG[\"R\"])\n",
    "\n",
    "    models = [\"iid_normal\", \"iid_t_fixed_nu\", \"garch11_t_fixed_nu\"]\n",
    "\n",
    "    for model_name in models:\n",
    "        cache_name = f\"partB_boot_{model_name}_R{Rb}_n{partB_n}_seed{CONFIG['seed']}_nu{CONFIG['t_df']}\"\n",
    "        npy_path = CACHE_DIR / f\"{cache_name}.npy\"\n",
    "\n",
    "        if npy_path.exists():\n",
    "            sr_sorted = np.load(npy_path)\n",
    "            cached = True\n",
    "        else:\n",
    "            cached = False\n",
    "            if model_name == \"iid_normal\":\n",
    "                model, res, params = sharpe_mc.fit_candidate(train_arr, \"iid_normal\")\n",
    "                mu_hat = float(res.params[\"mu\"])\n",
    "                sigma_hat = float(np.sqrt(res.params[\"sigma2\"]))\n",
    "                fit_summary[model_name] = {\"mu_hat\": mu_hat, \"sigma_hat\": sigma_hat, \"cached\": cached}\n",
    "\n",
    "                draws = mu_hat + sigma_hat * np.random.default_rng(CONFIG[\"seed\"] + 1).standard_normal((Rb, partB_n))\n",
    "                sr = draws.mean(axis=1) / draws.std(axis=1, ddof=1)\n",
    "\n",
    "            elif model_name == \"iid_t_fixed_nu\":\n",
    "                # Fixed nu: estimate mu/sigma from train, keep nu from config.\n",
    "                mu_hat = float(np.mean(train_arr))\n",
    "                sigma_hat = float(np.std(train_arr, ddof=1))\n",
    "                nu = float(CONFIG[\"t_df\"])\n",
    "                fit_summary[model_name] = {\"mu_hat\": mu_hat, \"sigma_hat\": sigma_hat, \"nu_fixed\": nu, \"cached\": cached}\n",
    "\n",
    "                rng = np.random.default_rng(CONFIG[\"seed\"] + 2)\n",
    "                z = rng.standard_t(df=nu, size=(Rb, partB_n)) / np.sqrt(nu / (nu - 2.0))\n",
    "                draws = mu_hat + sigma_hat * z\n",
    "                sr = draws.mean(axis=1) / draws.std(axis=1, ddof=1)\n",
    "\n",
    "            else:  # garch11_t_fixed_nu\n",
    "                model, res, params = sharpe_mc.fit_candidate(train_arr, \"garch11_t\")\n",
    "                params_sim = np.asarray(params, dtype=float).copy()\n",
    "                nu_hat_fit = float(params_sim[-1])\n",
    "                params_sim[-1] = float(CONFIG[\"t_df\"])  # closest fixed-nu approach\n",
    "                init_var = float(max(np.var(train_arr, ddof=1), 1e-8))\n",
    "\n",
    "                fit_summary[model_name] = {\n",
    "                    \"mu_hat\": float(params_sim[0]),\n",
    "                    \"omega_hat\": float(params_sim[1]),\n",
    "                    \"alpha_hat\": float(params_sim[2]),\n",
    "                    \"beta_hat\": float(params_sim[3]),\n",
    "                    \"nu_hat_fit\": nu_hat_fit,\n",
    "                    \"nu_used\": float(params_sim[-1]),\n",
    "                    \"note\": \"fixed nu not exposed by fitter; fitted params then replaced nu for simulation\",\n",
    "                    \"cached\": cached,\n",
    "                }\n",
    "\n",
    "                sr = np.empty(Rb, dtype=float)\n",
    "                np.random.seed(CONFIG[\"seed\"] + 3)\n",
    "                for i in tqdm(range(Rb), desc=f\"Part B {model_name}\"):\n",
    "                    sim = sharpe_mc.simulate_from_fit(\n",
    "                        model,\n",
    "                        params_sim,\n",
    "                        n=partB_n,\n",
    "                        burn=int(CONFIG[\"burn_B\"]),\n",
    "                        initial_value_vol=init_var,\n",
    "                    )\n",
    "                    s_hat, _, _ = sharpe_mc.sharpe_ratio(sim)\n",
    "                    sr[i] = s_hat\n",
    "\n",
    "            sr = sr[np.isfinite(sr)]\n",
    "            sr_sorted = np.sort(sr)\n",
    "            np.save(npy_path, sr_sorted)\n",
    "\n",
    "        if model_name not in fit_summary:\n",
    "            fit_summary[model_name] = {\"cached\": cached}\n",
    "\n",
    "        u = np.searchsorted(sr_sorted, obs_windows[\"S_obs\"].to_numpy(dtype=float), side=\"right\") / len(sr_sorted)\n",
    "        ks = stats.kstest(u, \"uniform\")\n",
    "        score = float(np.mean(np.abs(u - 0.5)))\n",
    "\n",
    "        for j, u_j in enumerate(u):\n",
    "            partB_rows.append({\n",
    "                \"model\": model_name,\n",
    "                \"window_id\": int(obs_windows.iloc[j][\"window_id\"]),\n",
    "                \"S_obs\": float(obs_windows.iloc[j][\"S_obs\"]),\n",
    "                \"pit_u\": float(u_j),\n",
    "                \"ks_stat\": float(ks.statistic),\n",
    "                \"ks_pvalue\": float(ks.pvalue),\n",
    "                \"pit_score\": score,\n",
    "                \"n_windows\": int(len(u)),\n",
    "                \"n_boot\": int(len(sr_sorted)),\n",
    "            })\n",
    "\n",
    "    results_partB = pd.DataFrame(partB_rows)\n",
    "\n",
    "partB_paths = save_df(results_partB, \"results_partB_pit\")\n",
    "fit_path = RUN_DIR / \"model_fit_summary.json\"\n",
    "fit_path.write_text(json.dumps(fit_summary, indent=2), encoding=\"utf-8\")\n",
    "SAVED_ARTIFACTS.append(str(fit_path.resolve()))\n",
    "\n",
    "print(\"Saved Part B:\")\n",
    "for p in partB_paths:\n",
    "    print(\"-\", p)\n",
    "print(\"-\", fit_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0338bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part B diagnostics view\n",
    "if results_partB.empty:\n",
    "    print(partB_reason if partB_reason else \"Part B skipped\")\n",
    "else:\n",
    "    diag = results_partB[[\"model\", \"ks_stat\", \"ks_pvalue\", \"pit_score\", \"n_windows\", \"n_boot\"]].drop_duplicates()\n",
    "    diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "676c4bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Part B PIT histogram figures\n"
     ]
    }
   ],
   "source": [
    "# Part B plot: PIT histogram per model\n",
    "if results_partB.empty:\n",
    "    print(\"No Part B plot (results empty)\")\n",
    "else:\n",
    "    for model_name, g in results_partB.groupby(\"model\"):\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        u = g[\"pit_u\"].to_numpy(dtype=float)\n",
    "        ax.hist(u, bins=np.linspace(0, 1, 11), density=True, alpha=0.75, edgecolor=\"black\")\n",
    "        ax.axhline(1.0, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_xlabel(\"PIT u\")\n",
    "        ax.set_ylabel(\"density\")\n",
    "        ax.set_title(f\"PIT histogram | {model_name}\")\n",
    "        fig.tight_layout()\n",
    "        save_fig(fig, f\"partB_pit_hist_{model_name}\")\n",
    "        plt.close(fig)\n",
    "    print(\"Saved Part B PIT histogram figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6862693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Part B ECDF figures\n"
     ]
    }
   ],
   "source": [
    "# Part B plot: ECDF(u) vs uniform per model\n",
    "if results_partB.empty:\n",
    "    print(\"No Part B ECDF plot (results empty)\")\n",
    "else:\n",
    "    for model_name, g in results_partB.groupby(\"model\"):\n",
    "        u = np.sort(g[\"pit_u\"].to_numpy(dtype=float))\n",
    "        y = np.arange(1, len(u) + 1) / len(u)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        ax.step(u, y, where=\"post\", label=\"ECDF(u)\")\n",
    "        ax.plot([0, 1], [0, 1], linestyle=\"--\", color=\"black\", label=\"Uniform\")\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_xlabel(\"u\")\n",
    "        ax.set_ylabel(\"ECDF\")\n",
    "        ax.set_title(f\"PIT ECDF | {model_name}\")\n",
    "        ax.legend(loc=\"lower right\")\n",
    "        fig.tight_layout()\n",
    "        save_fig(fig, f\"partB_pit_ecdf_{model_name}\")\n",
    "        plt.close(fig)\n",
    "    print(\"Saved Part B ECDF figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3eba4812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part A head:\n",
      "         dgp    n   S_true               method      bias     rmse  coverage_95  reject_rate_H0_S_le_0  se_ratio  psr_reject_rate  dsr_reject_rate\n",
      "0  garch11_t  120 0.000000                  dsr -0.001151 0.092662          NaN                    NaN       NaN              NaN              NaN\n",
      "1  garch11_t  120 0.000000       hac_newey_west -0.001151 0.092662     0.926000               0.062000  0.951211         0.050000              NaN\n",
      "2  garch11_t  120 0.000000  iid_normal_analytic -0.001151 0.092662     0.945000               0.050000  0.986850         0.050000              NaN\n",
      "3  garch11_t  120 0.000000                  psr -0.001151 0.092662     0.945000               0.050000  0.986850         0.050000              NaN\n",
      "4  garch11_t  120 0.500000                  dsr  0.022526 0.136823          NaN                    NaN       NaN              NaN              NaN\n",
      "\n",
      "Part B head:\n",
      "                model  window_id    S_obs    pit_u  ks_stat  ks_pvalue  pit_score  n_windows  n_boot\n",
      "0          iid_normal          0 0.126913 0.571000 0.571000   0.858000   0.071000          1    1000\n",
      "1      iid_t_fixed_nu          0 0.126913 0.538000 0.538000   0.924000   0.038000          1    1000\n",
      "2  garch11_t_fixed_nu          0 0.126913 0.161000 0.839000   0.322000   0.339000          1    1000\n",
      "\n",
      "Saved artifacts:\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/environment_versions.json\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partA_coverage_garch11_t.pdf\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partA_coverage_garch11_t.png\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partA_coverage_iid_normal.pdf\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partA_coverage_iid_normal.png\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partA_coverage_iid_t.pdf\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partA_coverage_iid_t.png\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partA_reject_garch11_t.pdf\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partA_reject_garch11_t.png\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partA_reject_iid_normal.pdf\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partA_reject_iid_normal.png\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partA_reject_iid_t.pdf\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partA_reject_iid_t.png\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partB_pit_ecdf_garch11_t_fixed_nu.pdf\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partB_pit_ecdf_garch11_t_fixed_nu.png\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partB_pit_ecdf_iid_normal.pdf\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partB_pit_ecdf_iid_normal.png\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partB_pit_ecdf_iid_t_fixed_nu.pdf\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partB_pit_ecdf_iid_t_fixed_nu.png\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partB_pit_hist_garch11_t_fixed_nu.pdf\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partB_pit_hist_garch11_t_fixed_nu.png\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partB_pit_hist_iid_normal.pdf\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partB_pit_hist_iid_normal.png\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partB_pit_hist_iid_t_fixed_nu.pdf\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/figures/partB_pit_hist_iid_t_fixed_nu.png\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/model_fit_summary.json\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/results_partA.csv\n",
      "- /workspaces/finance-data-download-test/notebooks/outputs/thesis_mvp/results_partB_pit.csv\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "print(\"Part A head:\")\n",
    "print(results_partA.head())\n",
    "\n",
    "print(\"\\nPart B head:\")\n",
    "print(results_partB.head())\n",
    "\n",
    "print(\"\\nSaved artifacts:\")\n",
    "for p in sorted(set(SAVED_ARTIFACTS)):\n",
    "    print(\"-\", p)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}